# Experiment settings
experiment:
  mode: inference
  seed: 10
  use_multi_gpu: true
  use_amp: true

# Directory paths
paths:
  output_dir: trained_models/baseline_rnn
  checkpoint_dir: trained_models/baseline_rnn/checkpoint
  dataset_dir: data/raw/hdf5_data_final

# Model architecture
model:
  n_input_features: 512
  n_units: 768
  rnn_dropout: 0.4
  rnn_trainable: true
  n_layers: 5
  patch_size: 14
  patch_stride: 4
  input_network:
    input_layer_dropout: 0.2
    input_trainable: true

# Training configuration
training:
  num_batches: 120000
  grad_norm_clip: 10
  early_stopping:
    enabled: false
    patience: 20
  
  # Optimizer settings
  optimizer:
    lr_max: 0.005
    lr_min: 0.0001
    lr_max_day: 0.005
    lr_min_day: 0.0001
    weight_decay: 0.001
    weight_decay_day: 0
    beta0: 0.9
    beta1: 0.999
    epsilon: 0.1
    
  # Learning rate scheduler settings
  scheduler:
    type: cosine
    total_steps: 120000
    warmup_steps: 1000
    total_steps_day: 120000
    warmup_steps_day: 1000

  # Checkpoint settings
  checkpoint:
    init_from: false
    path: null
    save_best: true
    save_all_val: false
    save_final: false
    save_val_metrics: true

# Dataset and loading configuration
dataset:
  batch_size: 64
  days_per_batch: 4
  n_classes: 41
  test_percentage: 0.1
  seed: 1
  num_workers: 4
  shuffle: false
  must_include_days: null
  feature_subset: null
  
  # Data augmentation and transforms
  transforms:
    smooth_data: true
    smooth_kernel_size: 100
    smooth_kernel_std: 2
    white_noise_std: 1.0
    constant_offset_std: 0.2
    random_walk_std: 0.0
    random_cut: 3

  # Session details
  sessions:
  - t15.2023.08.11
  - t15.2023.08.13
  - t15.2023.08.18
  - t15.2023.08.20
  - t15.2023.08.25
  - t15.2023.08.27
  - t15.2023.09.01
  - t15.2023.09.03
  - t15.2023.09.24
  - t15.2023.09.29
  - t15.2023.10.01
  - t15.2023.10.06
  - t15.2023.10.08
  - t15.2023.10.13
  - t15.2023.10.15
  - t15.2023.10.20
  - t15.2023.10.22
  - t15.2023.11.03
  - t15.2023.11.04
  - t15.2023.11.17
  - t15.2023.11.19
  - t15.2023.11.26
  - t15.2023.12.03
  - t15.2023.12.08
  - t15.2023.12.10
  - t15.2023.12.17
  - t15.2023.12.29
  - t15.2024.02.25
  - t15.2024.03.03
  - t15.2024.03.08
  - t15.2024.03.15
  - t15.2024.03.17
  - t15.2024.04.25
  - t15.2024.04.28
  - t15.2024.05.10
  - t15.2024.06.14
  - t15.2024.07.19
  - t15.2024.07.21
  - t15.2024.07.28
  - t15.2025.01.10
  - t15.2025.01.12
  - t15.2025.03.14
  - t15.2025.03.16
  - t15.2025.03.30
  - t15.2025.04.13
  
  dataset_probability_val: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]

# Logging and monitoring
logging:
  train_log_freq: 200
  val_log_freq: 2000
  log_individual_day_val: true
  save_val_logits: true
  save_val_data: false

# Evaluation/Inference settings
evaluation:
  model_path: trained_models/baseline_rnn/checkpoint/best_checkpoint.pt
  eval_type: val # Options: val, test
  save_csv: true
  gpu_number: -1 # -1 for CPU, or GPU index